## ğŸ” SVM Notes â€“ Rappels ClÃ©s

- SVM ne se contente pas de sÃ©parer les donnÃ©es, il **les sÃ©pare avec la plus grande marge possible**, ce qui amÃ©liore la **robustesse au bruit** et la **gÃ©nÃ©ralisation**.
- Le **scaling est crucial** avec les SVM (ex: `StandardScaler`) car ils sont **sensibles aux Ã©chelles**.
- **SVM est trÃ¨s sensible aux outliers**.

---

### âœ… InterprÃ©tation des scores
- Si `score > 0` â†’ prÃ©diction = classe 1 (positif)
- Plus le score est **Ã©loignÃ© de 0**, plus le modÃ¨le est **confiant**.

---

### ğŸ¯ Influence du paramÃ¨tre `C`
- `C=100`: essaie de parfaitement sÃ©parer les donnÃ©es â†’ marge Ã©troite, **risque de surapprentissage**.
- `C=1`: accepte quelques erreurs â†’ marge plus large, **meilleure gÃ©nÃ©ralisation**.

---

### ğŸŒ€ SVM Non LinÃ©aire et Kernels
- Un **SVM non linÃ©aire** est un SVM qui utilise le **kernel trick** pour apprendre des **frontiÃ¨res courbes**.
- Le **kernel polynomial** permet de projeter implicitement les donnÃ©es dans un espace de plus grande dimension.
- Le **kernel RBF** (Gaussian) utilise des **landmarks** et calcule des **similaritÃ©s** entre chaque point et les landmarks â†’ permet de bien sÃ©parer dans lâ€™espace projetÃ©.

> Le kernel trick permet de **calculer des produits scalaires dans un espace de dimension supÃ©rieure sans y aller explicitement**.

---

### ğŸ“ˆ SVR (Support Vector Regression)
- Version rÃ©gression du SVM.
- Essaie de prÃ©dire une fonction **plate** qui reste dans un **tube dâ€™erreur Â±Îµ**.
- `C` â†’ contrÃ´le la pÃ©nalitÃ© pour les grosses erreurs.
- `Îµ` â†’ dÃ©finit ce quâ€™est une erreur tolÃ©rable.
- TrÃ¨s utile pour gÃ©rer les **outliers sans les supprimer**.

---

### ğŸ’¥ Squared Hinge Loss
- `hinge = max(0, 1 - t*s)`  
- `squared_hinge = (max(0, 1 - t*s))Â²`
- La squared hinge loss **pÃ©nalise plus fortement** les erreurs â†’ peut aider Ã  mieux apprendre.

---

### âš™ï¸ Gradient Descent et SVM
| ModÃ¨le                        | Utilise Gradient Descent ? | Optimiseur                     |
|------------------------------|-----------------------------|--------------------------------|
| `LinearSVC`                  | âŒ                          | Coordinate Descent (LibLinear) |
| `SVC(kernel=...)`            | âŒ                          | SMO (LibSVM)                   |
| `SGDClassifier(loss='hinge')`| âœ…                          | Stochastic Gradient Descent    |

> âœ… `SGDClassifier` est **le seul modÃ¨le SVM dans sklearn qui utilise le gradient descent.`

---
